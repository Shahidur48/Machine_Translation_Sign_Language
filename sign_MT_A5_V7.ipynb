{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRRgPbFfp1oT"
      },
      "source": [
        "# Machine Translation Competition\n",
        "\n",
        "**Contributor: Md Shahidur Rahaman**\n",
        "\n",
        "*This work is inspired from the google research code: This study uses Effective Approaches to Attention-based Neural Machine Translation to train a sequence to sequence (seq2seq) model for Spanish to English translation.*\n",
        "\n",
        "link : *https://www.tensorflow.org/text/tutorials/nmt_with_attention?fbclid=IwAR3Aq7a8iyip3Fx-OlUDAtp81UGIhm-bGX4dhVS-QdpdbIbq6S0a-ipbUEU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTFNq6Tnt_d0",
        "outputId": "0418efe4-ab2b-46c7-deda-02262800fafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-text==2.8.* in /usr/local/lib/python3.7/dist-packages (2.8.2)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.25.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.44.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "#TF.Text is a TensorFlow library of text related operation, modules, and subgraphs.\n",
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "6HkFjK0YuzGv"
      },
      "outputs": [],
      "source": [
        "#Importing package Libraries\n",
        "import numpy as np\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "M7lG9PFxu1sZ"
      },
      "outputs": [],
      "source": [
        "#Switching between custom to Builtin Implementation\n",
        "use_builtins = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "7vPO02EMu3lb"
      },
      "outputs": [],
      "source": [
        "#Checking the Shape for the model\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "      if old_dim is None:\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nCqHoeAsBUou"
      },
      "outputs": [],
      "source": [
        "def getdata(path, removecomma):\n",
        "    datalist = []\n",
        "    with open(path,encoding=\"unicode_escape\") as f:\n",
        "        row_data = f.read().split(\"\\n\")[:-1]\n",
        "        if removecomma==1:\n",
        "            row_data = row_data.replace(\",\", \" \")\n",
        "            \n",
        "        datalist.append(row_data)\n",
        "    return row_data\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "aDBCSz63BUov"
      },
      "outputs": [],
      "source": [
        "eng_file_path = \"sentencesTrain.txt\"\n",
        "gloss_file_path = \"tokensTrain.txt\"\n",
        "\n",
        "inp = getdata(eng_file_path,0)\n",
        "targ_temp = getdata(gloss_file_path,0)\n",
        "\n",
        "targ = []\n",
        "for data in targ_temp:\n",
        "    data  = data.replace(\",\", \" \")\n",
        "    targ.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-righ4I-YNC",
        "outputId": "1aa693f5-eed4-4eec-e8ca-0058908c68df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['(P)PARTY START WHICH TIME EIGHT TIME NINE (P)PARTY START WHICH TIME', '(G/Q)POSS-1p SISTER (2h)IX-3p:i tube skipping on water IX-1p GO-BY-BOAT IX-1p LOOK MAKE REALLY person flips off IX-1p STOP SISTER (2h)IX-3p:i tube skipping on water GO-BY-BOAT MAKE STOP']\n",
            "['When does the party start, at 8 or 9?', 'When my sister goes water tubing, I will have to watch her and make sure to stop the boat when she falls off.']\n"
          ]
        }
      ],
      "source": [
        "print(targ[0:2])\n",
        "print(inp[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "bfF3KH92vozg"
      },
      "outputs": [],
      "source": [
        "#Shuffling and batching from the arrays of string to tf.data.Dataset strings\n",
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFfFwhWsvrUw",
        "outputId": "3c414f6c-f57b-4034-b856-69694b66728b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'Who loves watching fireworks?'\n",
            " b'If my boss summons me, everyone will know I\\xc2\\x92m in trouble.'\n",
            " b'Does the party tonight start at 8 or 9?' b'Have Jack and Sue met?'\n",
            " b'Did someone win the lottery?'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'WHO KISS-FIST LOOK FIREWORKS'\n",
            " b\"#IF POSS-1p BOSS IX-loc:i SUMMON IX-1p listen up GUARANTEE EACH+ONE-pl-arc ' KNOW-THAT IX-1p IN TROUBLE SUMMON GUARANTEE EACH ' IN TROUBLE\"\n",
            " b'(P)PARTY_2 NIGHT START EIGHT NINE part:indef (P)PARTY_2 NIGHT START part:indef'\n",
            " b'fs-JACK fs-SUE MEET FINISH MEET FINISH'\n",
            " b'fs-LOTTERY IX-loc:i SOMETHING/ONE WIN QMwg WIN'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "#Data Checking\n",
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Ve7HDqDovv5Q"
      },
      "outputs": [],
      "source": [
        "#Standardization for the Unicode using  text standardization function\n",
        "def tf_lower_v3(text):\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "4rCbQ4Y6v2BX"
      },
      "outputs": [],
      "source": [
        "#Converting input sequence to sequence of token\n",
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_v3,\n",
        "    max_tokens=max_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opLEPQ3Tv4RY",
        "outputId": "0b4c4199-8eb5-463b-af45-17946967bcfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', 'the', 'I', 'to', 'If', 'a', 'is']"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text_processor.adapt(inp)\n",
        "input_text_processor.get_vocabulary()[:10] # Checking the first 10 vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjiwTRcKwB0p",
        "outputId": "acd71bf8-c812-48df-e83e-ad8fb5edc76d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 'IX-1p',\n",
              " 'FRIEND',\n",
              " 'IX-3p:i',\n",
              " 'part:indef',\n",
              " 'IX-loc:i',\n",
              " '(1h)part:indef']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Adapting the Sequence\n",
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_v3,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHPWYqXcwC4x",
        "outputId": "22fdcf64-1033-4073-b148-950efe045569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[  2,  17,  62, 318, 230,   3,   0,   0,   0,   0],\n",
              "       [  2,   7,  10, 243, 950, 370, 139,  11,  80, 453],\n",
              "       [  2, 143,   4,  65, 907,  69,  28, 461,  93, 460]])>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Converting a batch of strings into a batch of token IDs\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mDrjPTrWwFJR",
        "outputId": "9f81e142-f750-4063-eea1-08f07bcf4e50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[START] Who loves watching fireworks? [END]                  '"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Converting the ID-Tokens to Text\n",
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "kmZ0s8UZwKyx"
      },
      "outputs": [],
      "source": [
        "#Defining the Constant\n",
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "5QwK1T59wbpA"
      },
      "outputs": [],
      "source": [
        "#Encoder takes a list of token IDs and teturns the processed sequence with internal state which will be used to initialize the decoder\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpjMHsRswcvZ",
        "outputId": "ae729106-1c36-4329-b378-634212e4c27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch, shape (batch): (64,)\n",
            "Input batch tokens, shape (batch, s): (64, 24)\n",
            "Encoder output, shape (batch, s, units): (64, 24, 1024)\n",
            "Encoder state, shape (batch, units): (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "0tioEGXSwesZ"
      },
      "outputs": [],
      "source": [
        "#This tutorial uses Bahdanau's additive attention. TensorFlow includes implementations of both as layers.Attention and layers.AdditiveAttention. \n",
        "#The class below handles the weight matrices in a pair of layers.Dense layers, and calls the builtin implementation.\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "rLEJVVMmwjXx"
      },
      "outputs": [],
      "source": [
        "#Creating a BahdanauAttention layer:\n",
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxQTqzOzwlOh",
        "outputId": "77c27c0b-8835-468f-f572-07dab3849fcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 24])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(example_tokens != 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XucK4JH5wmsh",
        "outputId": "8e140d9e-8d56-43ca-9f0e-962821d62fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 24)\n"
          ]
        }
      ],
      "source": [
        "#vectorized implementation of the attention layer lets you pass a batch \n",
        "#of sequences of query vectors and a batch of sequence of value vectors. \n",
        "#This will return a batch of sequences of result vectors the size of the queries.\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "LtuBw6AwwotB",
        "outputId": "ecdf0b30-ed57-44c0-dd36-b7006fae0f3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrNukkygxFix",
        "outputId": "5e631b28-2c5b-44d9-a05d-95abedb66d32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([64, 2, 24])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "CpjBOBL1xGTf"
      },
      "outputs": [],
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S5T4koFJxIPq",
        "outputId": "816ab209-4872-4215-cea4-01f2827f2960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5904d49d50>]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title\n",
        "plt.suptitle('Attention weights for one sequence')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "a1 = plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlim(plt.xlim())\n",
        "plt.xlabel('Attention weights')\n",
        "\n",
        "a2 = plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlabel('Attention weights, zoomed')\n",
        "\n",
        "top = max(a1.get_ylim())\n",
        "zoom = 0.85*top\n",
        "a2.set_ylim([0.90*top, top])\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Rik9s9cQxKmy"
      },
      "outputs": [],
      "source": [
        "#The decoder will predict the next output token.\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Ro39vo8HxVsp"
      },
      "outputs": [],
      "source": [
        "#This layer's call function accepts and returns several tensors. Sort them into basic container classes.\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "ZoMstJe6xWiz"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "H4UBQ3uMxYyj"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "UxT_zNAJxbKr"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "kDKnNJZgxcuy"
      },
      "outputs": [],
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QsNs6hExei3",
        "outputId": "20690ba9-9bc7-4aba-d18a-fa81f9ac5b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 1294)\n",
            "state shape: (batch_size, dec_units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "oZFfUgMmxlsP"
      },
      "outputs": [],
      "source": [
        "#Sample a token according to the logits:\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3fMqGBfxnFO",
        "outputId": "34954091-553f-42e9-ffee-f50b42fe29f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['KEEP++++'],\n",
              "       ['fs-TOO'],\n",
              "       ['STUCK'],\n",
              "       ['(1h)SIT'],\n",
              "       ['NINE']], dtype='<U33')"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Extz_k8Gxpa-"
      },
      "outputs": [],
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzHr4VTHxrVm",
        "outputId": "ccf8c72f-7c13-484e-aa0b-c7fee43abdc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['BUOY-2'],\n",
              "       ['#VOL'],\n",
              "       ['applying'],\n",
              "       ['GUITAR'],\n",
              "       ['POSS-2p']], dtype='<U33')"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "LfD37Uv3xtxQ"
      },
      "outputs": [],
      "source": [
        "#Defining the loss function\n",
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "P3SgVWo2xu0m"
      },
      "outputs": [],
      "source": [
        "#The training process will be implemented as the train_step method on this model\n",
        "#The train step function acts as a wrapper for the _train step implementation, which will be provided later. \n",
        "#To facilitate debugging, this wrapper offers a switch for turning on and off tf.function compilation.\n",
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "RH6m2U-Vxwsv"
      },
      "outputs": [],
      "source": [
        "#Preprocessing\n",
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "BPRdz7jyxzb-"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "8rd7KgEix0Jg"
      },
      "outputs": [],
      "source": [
        "#Except for actually executing the decoder, the '_train step' function added below handles the other steps:\n",
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "WGuhWlRIx12J"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._train_step = _train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "l5qZ8M7fx3zw"
      },
      "outputs": [],
      "source": [
        "#The _loop step method runs the decoder and calculates the incremental loss and new decoder state (dec state).\n",
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "QGPZypjtx5Vo"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Pbx2k-JBx66w"
      },
      "outputs": [],
      "source": [
        "#Creating a TrainTranslator and configure it for Model-based training. technique of compilation:\n",
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Retn8Fu4x8hI",
        "outputId": "1e32809b-b116-491c-dd47-d0c5f4f83acb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.165493475060845"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwp9sMRMx94R",
        "outputId": "ceb5b406-fd78-4409-9ced-be2b3c2d891e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.6535916>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.625939>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.578363>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.450348>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.9733276>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.371425>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.313323>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.5262647>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.5142336>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.3693147>}\n",
            "\n",
            "CPU times: user 29.2 s, sys: 425 ms, total: 29.6 s\n",
            "Wall time: 48.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "i2d64yEqygGA"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "ih02KzieykyN"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "PcZDKYYEymsk"
      },
      "outputs": [],
      "source": [
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7oMzjo2yoQk",
        "outputId": "4ba042c3-c306-43f6-f5a3-99ad8d61719d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.2609262>}"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Functional Tracing\n",
        "translator.train_step([example_input_batch, example_target_batch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_3lJuuPyueM",
        "outputId": "26b6d0d0-3928-4e0b-f9d2-73853abe1da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.223023>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.095852>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.9646335>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.887116>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8479543>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8016653>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.789174>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.762685>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.737216>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.724595>}\n",
            "\n",
            "CPU times: user 10.5 s, sys: 1.21 s, total: 11.7 s\n",
            "Wall time: 7.33 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "MGf3foCIzkZl",
        "outputId": "323f77aa-7c54-4ac2-cdce-ea157a9c3c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f59043a62d0>]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "tKxewQGVzIU9"
      },
      "outputs": [],
      "source": [
        "#Build a fresh copy of the Model\n",
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "Cok_g9VmzKvU"
      },
      "outputs": [],
      "source": [
        "#Model Training\n",
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5NZlq7zzO3A",
        "outputId": "4954f161-e517-4d61-d7bc-9f1c2333392d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "11/11 [==============================] - 17s 809ms/step - batch_loss: 6.3622\n",
            "Epoch 2/45\n",
            "11/11 [==============================] - 9s 854ms/step - batch_loss: 5.7671\n",
            "Epoch 3/45\n",
            "11/11 [==============================] - 9s 832ms/step - batch_loss: 5.4632\n",
            "Epoch 4/45\n",
            "11/11 [==============================] - 9s 842ms/step - batch_loss: 5.2761\n",
            "Epoch 5/45\n",
            "11/11 [==============================] - 9s 847ms/step - batch_loss: 5.1300\n",
            "Epoch 6/45\n",
            "11/11 [==============================] - 9s 858ms/step - batch_loss: 4.9761\n",
            "Epoch 7/45\n",
            "11/11 [==============================] - 9s 839ms/step - batch_loss: 4.7777\n",
            "Epoch 8/45\n",
            "11/11 [==============================] - 9s 802ms/step - batch_loss: 4.5222\n",
            "Epoch 9/45\n",
            "11/11 [==============================] - 9s 843ms/step - batch_loss: 4.2393\n",
            "Epoch 10/45\n",
            "11/11 [==============================] - 9s 820ms/step - batch_loss: 3.9504\n",
            "Epoch 11/45\n",
            "11/11 [==============================] - 10s 858ms/step - batch_loss: 3.6748\n",
            "Epoch 12/45\n",
            "11/11 [==============================] - 9s 821ms/step - batch_loss: 3.3390\n",
            "Epoch 13/45\n",
            "11/11 [==============================] - 9s 825ms/step - batch_loss: 3.0369\n",
            "Epoch 14/45\n",
            "11/11 [==============================] - 9s 840ms/step - batch_loss: 2.7242\n",
            "Epoch 15/45\n",
            "11/11 [==============================] - 9s 830ms/step - batch_loss: 2.4148\n",
            "Epoch 16/45\n",
            "11/11 [==============================] - 9s 823ms/step - batch_loss: 2.1284\n",
            "Epoch 17/45\n",
            "11/11 [==============================] - 9s 804ms/step - batch_loss: 1.8534\n",
            "Epoch 18/45\n",
            "11/11 [==============================] - 9s 839ms/step - batch_loss: 1.6070\n",
            "Epoch 19/45\n",
            "11/11 [==============================] - 9s 860ms/step - batch_loss: 1.3681\n",
            "Epoch 20/45\n",
            "11/11 [==============================] - 9s 812ms/step - batch_loss: 1.1937\n",
            "Epoch 21/45\n",
            "11/11 [==============================] - 9s 807ms/step - batch_loss: 1.0120\n",
            "Epoch 22/45\n",
            "11/11 [==============================] - 10s 910ms/step - batch_loss: 0.8739\n",
            "Epoch 23/45\n",
            "11/11 [==============================] - 9s 806ms/step - batch_loss: 0.7294\n",
            "Epoch 24/45\n",
            "11/11 [==============================] - 9s 825ms/step - batch_loss: 0.6078\n",
            "Epoch 25/45\n",
            "11/11 [==============================] - 9s 823ms/step - batch_loss: 0.5138\n",
            "Epoch 26/45\n",
            "11/11 [==============================] - 9s 813ms/step - batch_loss: 0.4192\n",
            "Epoch 27/45\n",
            "11/11 [==============================] - 9s 822ms/step - batch_loss: 0.3459\n",
            "Epoch 28/45\n",
            "11/11 [==============================] - 9s 842ms/step - batch_loss: 0.2953\n",
            "Epoch 29/45\n",
            "11/11 [==============================] - 9s 818ms/step - batch_loss: 0.2331\n",
            "Epoch 30/45\n",
            "11/11 [==============================] - 9s 805ms/step - batch_loss: 0.1898\n",
            "Epoch 31/45\n",
            "11/11 [==============================] - 9s 842ms/step - batch_loss: 0.1601\n",
            "Epoch 32/45\n",
            "11/11 [==============================] - 9s 801ms/step - batch_loss: 0.1329\n",
            "Epoch 33/45\n",
            "11/11 [==============================] - 9s 835ms/step - batch_loss: 0.1120\n",
            "Epoch 34/45\n",
            "11/11 [==============================] - 9s 847ms/step - batch_loss: 0.0937\n",
            "Epoch 35/45\n",
            "11/11 [==============================] - 9s 821ms/step - batch_loss: 0.0842\n",
            "Epoch 36/45\n",
            "11/11 [==============================] - 9s 842ms/step - batch_loss: 0.0741\n",
            "Epoch 37/45\n",
            "11/11 [==============================] - 9s 804ms/step - batch_loss: 0.0676\n",
            "Epoch 38/45\n",
            "11/11 [==============================] - 9s 841ms/step - batch_loss: 0.0581\n",
            "Epoch 39/45\n",
            "11/11 [==============================] - 9s 802ms/step - batch_loss: 0.0546\n",
            "Epoch 40/45\n",
            "11/11 [==============================] - 9s 858ms/step - batch_loss: 0.0480\n",
            "Epoch 41/45\n",
            "11/11 [==============================] - 9s 828ms/step - batch_loss: 0.0434\n",
            "Epoch 42/45\n",
            "11/11 [==============================] - 9s 826ms/step - batch_loss: 0.0400\n",
            "Epoch 43/45\n",
            "11/11 [==============================] - 9s 790ms/step - batch_loss: 0.0387\n",
            "Epoch 44/45\n",
            "11/11 [==============================] - 9s 824ms/step - batch_loss: 0.0371\n",
            "Epoch 45/45\n",
            "11/11 [==============================] - 9s 822ms/step - batch_loss: 0.0343\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f590436ab50>"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Running with 45 epochs\n",
        "train_translator.fit(dataset, epochs=45,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "HKaOtpUE2u-U",
        "outputId": "b45d9a24-01f3-4642-b40c-878639127662"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcZZn38e9dS3f1ms7SSci+kBASIAnEEHYQUUAUcWcY3EVHHPBye8UZ13GUGWd01HFUFBeUkWFRQQGRTVERMImEbCyBBJKQpDtbd3rf7vePOl1d1V3pdJI6Vd1dv8911ZVznnOq6j5Jpe56lvM85u6IiEjxihQ6ABERKSwlAhGRIqdEICJS5JQIRESKnBKBiEiRUyIQESlyoSUCM0uY2RNmtsbM1pvZF7KcU2pm/2dmm8zscTObFVY8IiKSXZg1gnbgle6+GFgCXGhmK/qd815gn7sfC3wd+LcQ4xERkSxCSwSe1BTsxoNH/7vXLgV+EmzfDpxvZhZWTCIiMlAszBc3syiwCjgW+La7P97vlKnAVgB37zKzBmA8sLvf61wFXAVQUVFxyoIFC8IMWwbR1tnNc3VNzBhXzt7mDprauwAYV1FCY2snxx9TXeAIRSSbVatW7Xb32mzHQk0E7t4NLDGzGuCXZnaCu687gte5AbgBYNmyZb5y5cocRypDtXVvC2f9+8N0G8yvTjBtbBk/ec9y/vN3z3LLEy+x8osXFjpEEcnCzF482LG8jBpy9/3Aw0D/b4ntwHQAM4sBY4A9+YhJjkxlafK3Q4/DjoY2xleUUl4SIxGP0NrZjeauEhl5whw1VBvUBDCzMuAC4Ol+p90FvDPYfjPwkOubZFirKM2sRFYmkvtl8Sg9Dp3d+ucTGWnCbBo6BvhJ0E8QAW5199+Y2ReBle5+F3Aj8FMz2wTsBd4eYjySAyWxzN8O1Yk4AIl4FIDWzu4B54jI8BZaInD3p4ClWco/m7bdBrwlrBgkfNPHlQF9iaC9sxvK4oUMSUQOk366yVGZPrYcyKwRiMjIokQgR2X6uGQiKAsSQVtnT8bxjq4eXvetP/HnTbsHPFdEhgclAjlsS6bXpLb7moaSH6X+NYLt+1tZu72BT/9ybf4CFJHDEup9BDI6/erqM/j9M3Xcv2EX5SV9o4YgecNZup5gEFhEN4yLDFtKBHJEzj1uIuceNzG1nygZ2Efw8v5WrvxB8mZy5QGR4UtNQ5ITiVjaqKHAtx56jpcb2gCIKhOIDFtKBJITZVlqBOm3BioPiAxfSgSSE72dxemjhtITgfoIRIYvJQLJid7O4taOvhpBT1omUCIQGb6UCCQnem8oa+vKfkNZRJ80kWFLo4YkJ0qD+YXaOrr5n99vImqWsQqRagQiw5cSgeSEmaWmov7mQ5sAeOPJUzOOi8jwpAq75ExZPJo5xURalSCqPCAybCkRSM4k4tHM4aNpx9Q0JDJ8KRFIziTiUW5ftS3rMSUCkeFLiUBypr3fPEPp8w4pD4gMX0oEkjMNrZ0Z+/UH2lPbqhGIDF9KBJIzzR2ZNYK69ESgT5rIsKX/nhKal/a2pLZVIxAZvpQIJC/S5x0SkeFFiUDyoqun59AniUhBKBFIzjzw0bNT23NqKzKOdfeoSiAyXCkRSM4cO7GKxdPGAPDJ1yzIONalRCAybCkRSE6dGCSC/jWCrm4lApHhSolAcuozlyzkf99/KvMnVXHHP5yeKleNQGT4UiKQnCqNRTl97gQATpk5NlXerc5ikWFLiUBCtXRGDaCmIZHhLLREYGbTzexhM9tgZuvN7Nos55xrZg1m9mTw+GxY8Uhh/PJDZ3DZ0qlqGhIZxsJcmKYL+Ji7rzazKmCVmd3v7hv6nfdHd78kxDikwKIR0/BRkWEstBqBu+9w99XB9gFgIzB18GfJaBSLGJ3dfX0EPUoKIsNKXvoIzGwWsBR4PMvh08xsjZnda2aL8hGP5Fcs2lcjuHftDuZ8+h62ps1DJCKFFXoiMLNK4A7gI+7e2O/wamCmuy8GvgX86iCvcZWZrTSzlfX19eEGLDkXi0RSfQT3rd8JwB+eTf477m3uKFhcIpIUaiIwszjJJHCzu/+i/3F3b3T3pmD7HiBuZhOynHeDuy9z92W1tbVhhiwhiEaMrqBpaGJ1AoDfP1PHFT94jJP/5X6er28qZHgiRS+0zmIzM+BGYKO7f+0g50wGdrm7m9lykolpT1gxSWHEIpaqEewLagAPbKxLHd/V0Mbc2sqCxCYi4Y4aOgO4ElhrZk8GZZ8GZgC4+3eBNwP/YGZdQCvwdndNWDzapPcR7MnSFNTU3pXvkEQkTWiJwN3/BAy6Gom7/zfw32HFIMNDNOgjcHf2NPWtWjaxqpS6A+209FvZTETyS3cWS+hikeTvgU/c/hS7m/pqBGPK4oBqBCKFpkQgodu+rxWA21dtY09zO7PGlwNQUZqskDYrEYgUlBKBhK4q0dcC2dbZw6Rg5NDEqlLMlAhECk2JQEL3sVcfx4o541L75x8/kQ+cPYcvveEEyuNRmtVHIFJQSgQSurKSKGfP77v/ozoR57qLj2didYKK0phqBCIFpkQgeTGxKpHa7u0bAKgsjamzWKTAlAgkLyZWlaa2K0qjqe3y0qiGj4oUmBKB5MWEyr5EUF7SVyOoKFGNQKTQlAgkL8ZVlKS2K9ITgfoIRApOiUDyYmxFPLWd3jRUFo/S1jmwaeivW/byL7/pv4aRiIRBiUDyojTW9+Wf3llcEovQmWU947d89y/c+KfNaOopkfApEUjelZf0JYV41Ojo6jnouVrMTCR8SgSSd+mdxckawcETQVfPwY+JSG4oEUjeRSN9k9LGo5FBawRa9F4kfEoEUlAl0Qgdg9YIlAhEwhbmwjQiGR762DlsC2Yi7VUSSyYCdye5qF2m7iwdySKSW0oEkjdzaiuZ029Jyng0gnuyCSgWTSaC9D4D1QhEwqemISmokljyI5g+hHR/S2dqW30EIuFTIpCCikeTH8H0DuN9LX2rmGnUkEj4lAikoEqC5qD0DuO9aQvcd6mPQCR0SgRSUL1NQ19/4FluXbkVgP0ZNQIlApGwKRFIQfU2Df3v4y/xwz9tBmBvs/oIRPJJiUAKqrdGAPDMrgPsbGhjd1N7qkx9BCLh0/BRKajeGgGAO6z4yoMZx1UjEAmfagRSUOk1gmzURyASPiUCKaiS6OAfQdUIRMKnRCAFld40lJ4UjptUBWj4qEg+qI9ACiq9aehn7zuV4yZV8dT2/ZREI7zthsdUIxDJg9BqBGY23cweNrMNZrbezK7Nco6Z2TfNbJOZPWVmJ4cVjwxP8WjfRHMTKksYUx7nrHm1xIME0X/U0Ffve5onNu/Na4wio12YTUNdwMfcfSGwArjazBb2O+ciYF7wuAr4TojxyDBUmlYjGFPWt65xLFizIL1G0NPjfPvh53nr9/6SvwBFikBoicDdd7j76mD7ALARmNrvtEuBmzzpMaDGzI4JKyYZftL7CMZVlKS2exevSR811NTRlb/ARIpIXjqLzWwWsBR4vN+hqcDWtP1tDEwWmNlVZrbSzFbW19eHFaYUQHoiSF+PIBYJmobSOosPtPUlghYlBZGcCT0RmFklcAfwEXdvPJLXcPcb3H2Zuy+rra3NbYBSUAe7j6CvRtDXR3CgrW/qiTVbG8INTKSIhJoIzCxOMgnc7O6/yHLKdmB62v60oEyKRG8fwVnzJmSU93Yip/cRpNcI1GEskjuhDR+1ZD3/RmCju3/tIKfdBXzYzG4BTgUa3H1HWDHJ8FOViHPrB07jhKnVGeXZ+gjSawSrXtqXnwBFikCY9xGcAVwJrDWzJ4OyTwMzANz9u8A9wMXAJqAFeHeI8cgwtXz2uAFlvX0E2WoE08aW0djaOeA5InJkQksE7v4nYOBq5JnnOHB1WDHIyJVeI3B3unucxiARjKsoyVjXWESOju4slmGp9z6Cz/xqHfWNbXzzoU38w7lzARhbXsLOhrZChicyqmiuIRmWoml3HH/zoU0AbK5vJhYxqhIxOrVOgUjOKBHIsNRbI0jX0NpJVSJGPBpR05BIDikRyLAUzZIIdje1U5WIE4+aZiUVySElAhmWekcNpas70E5VIkYsGqFTiUAkZ5QIZFjKUiHoaxqKmJqGRHJIiUCGpfR5h9Ilm4YidCkRiOSMEoGMKGoaEsk9JQIZUaoTcUqipuGjIjmkRCAjSm+NwF0L24vkihKBjCjJRJDsP1CHsUhuDHmKCTM7HZiV/hx3vymEmEQOqrI0nlqUprO7h0Q8mnF88+5mJlSWUJWIZ3u6iGQxpBqBmf0U+A/gTOAVwWNZiHGJcM81Z/GxC+ZnlFUlYqm7jvt3GLd2dHPef/yej9+2Jm8xiowGQ60RLAMWBrOFiuTFwinVbN7dnFE2Y1w5DcEU1P2HkP5uw04AXqjPfI6IDG6ofQTrgMlhBiKSTWUi87fKiVPHUBKsc9yZ1ln84p5mrr0luezF0hk1+QtQZBQYao1gArDBzJ4A2nsL3f31oUQlEqgs7fuIfuH1i4hErK+zuKuvRrDqxb4Vy6JZpqcQkYMbaiL4fJhBiBxMVVAjmDGunHeePguAWFAjSF/YfsPLjZTGIowpi+uuY5HDNKRE4O5/MLOZwDx3f8DMyoHooZ4ncrTKglFB6UNFS4IaQUdXX9PQupcbWDC5ir0tHRnrHIvIoQ111ND7gduB7wVFU4FfhRWUSK/qYBjosll96xr3zkzaWyPY0dDKE5v3csaxE4hHIkoEIodpqE1DVwPLgccB3P05M5sYWlQigTHlcX77kbOYNb4iVdZ3Q1nyC//BjXX0OLz5lGncv2GXmoZEDtNQE0G7u3f0zghpZjFAP7skLxZMrs7YT40aCr7we4eTTqkp04R0IkdgqMMr/mBmnwbKzOwC4Dbg1+GFJXJwqc7ibqehpZMX6puJRozSWIR41OjWhHQih2WoNYJPAe8F1gIfAO5x9++HFpXIIOJpcw2dfv2DNHd0U52IYWZEI6Y+ApHDNOTho+7+WeD7AGYWNbOb3f2K8EITyS6e1jTU3NENQEVwv0E8ooXtRQ7XUJuGppvZdQBmVgLcATwXWlQig+jtLN7d1JEqKy+Jpo5pYXuRwzPURPAe4MQgGfwG+IO7fz60qEQG0VsjWLu9IVUWDSaiU9OQyOEbtGnIzE5O2/0GyfsI/kyy8/hkd18dZnAi2cSD+wjqGttSZb1f/vFoJOOOYxE5tEP1Efxnv/19wMKg3IFXHuyJZvZD4BKgzt1PyHL8XOBOYHNQ9At3/+LQwpZiVlGabAbatq81VdYTJIJYRE1DIodr0ETg7ucdxWv/GPhvYLDFa/7o7pccxXtIEaopLyFi8MLuplRZdzBDeiya2TT0+bvW8/jmvdx77Vl5j1NkpBjqFBNjzOxrZrYyePynmY0Z7Dnu/giwNydRiqSJRoxxFaUZN451d/fWCCIZdxb/+NEtbNzRmPcYRUaSoXYW/xA4ALw1eDQCP8rB+59mZmvM7F4zW3Swk8zsqt4kVF9fn4O3lZFuQmVJxn5vLSAWtax3FveoA1nkoIaaCOa6++fc/YXg8QVgzlG+92pgprsvBr7FIJPYufsN7r7M3ZfV1tYe5dvKaFBbVQpAVXD/QE/QNBSPROjO8qV/oK0rf8GJjDBDTQStZnZm746ZnQG0DnL+Ibl7o7s3Bdv3AHEzm3A0rynFY3xFskYwY3w5AO8+YzYA0ajR1dPDxh2NGTeW7W3pGPgiIgIM/c7iDwI3pfUL7APeeTRvbGaTgV3u7ma2nGRS2nM0rynFY0JlskZQUx5ny/WvTZXHI8bupg4u+sYfed+Zs1Pl+1o6mE3FgNcRkaEngkZ3X2xm1ZD8NW9mswd7gpn9HDgXmGBm24DPAfHg+d8F3gz8g5l1kaxdvN3d1ZArQ3LW/Fp+8KfN7GhoyyjvnZAOYGXa8pX7mlUjEDmYoSaCO4CT3T19+MXtwCkHe4K7Xz7YC7r7f5McXipy2M6ZX8s/v/Z4Fk3JHLwWC+4wBkj/XbGvpTNvsYmMNIe6s3gBsAgYY2ZvTDtUDSTCDEzkUN531sDxCr3zEAG0BBPSAWzfd1RdWiKj2qFqBMeRvDu4BnhdWvkB4P1hBSVypHqXsQRobu8bKfSjRzfz6kWTOP6Y6mxPEylqhxo1VA58HLjE3d+d9rjG3R/NQ3wihyW9aagpSAQfvWA+PT3Ol+/ZWKiwRIa1QyWCGSRXI/t3M/u8mZ1qvetVigxD6Z3FvWsVnDh1DK9eNJmndx7I+pzm9i4e3LgrL/GJDEeDJgJ3/zd3fyVwMbCG5HTUq83sf83sHWY2KR9BigxVPK2PoPfGspryOPMnVVJ/oJ39We4n+MTta3jvT1by4p7mvMUpMpwM6YYydz/g7r909w+4+1LgS0Atg08oJ5J30UhmhbW2qpSTptUwb2IVAM/uahrwnI07kjUFrWMgxWrQRGBmf5+2fUbvtrtvANrd/TUhxiZy2NKbhgBed9IUohFj6tgyAOoOtA14Tmva6CKRYnSoGsFH07a/1e/Ye3Ici8hRi/erEbxh6RQAyuLJNQzaOgcuWtPWlUwEWutYitWhho/aQbaz7YsUXG/jzrSxZbx12XROnJq84aw0nvzN09o58Nd/W1DW2aWmISlOh0oEfpDtbPsiBbepLtkHcPnyGVx93rGp8t4aQXvWRJCsCXSoRiBF6lCJYIGZPUXy1//cYJtg/2inoRbJuStOncHGHY1cceqMjPJEkAgG6w/o6FIikOJ0qESwGJgEbO1XPh3YGUpEIkdhTm0l//v+FQPK49EI0Yil+gOyUR+BFKtDdRZ/HWhw9xfTH0BDcExkxCiLRzM6i7t7nHvW7kjtKxFIsTpUIpjk7mv7FwZls0KJSCQkiXgko7P4pr9s4UM3r07tKxFIsTpUIqgZ5FhZLgMRCVsiHk2NEILM9QoA2tVHIEXqUIlgpZkNmGXUzN4HrAonJJFw9E8Ea7c1ZBzPtui9SDE4VGfxR4BfmtkV9H3xLwNKgMvCDEwk19L7CNx9wF3GahqSYnWoSed2ufvpwBeALcHjC+5+mrtr1JCMKIl4hLbObprauzj1yw/S1tnDdRctYOU/vwpQIpDiNaSlKt39YeDhkGMRCVUiHuXFPS286X8epe5AOwDjK0spiSV/D+k+AilWQ12zWGTES8SjvLS3JaNsfGUJJcFEdbqzWIrVkKahFhkNeu8uTldbWUo8SASaa0iKlRKBFI2y+MCP+/jKEqIRIxqxrH0E3T2uvgMZ9ZQIpGj0Tjx3ysyxXHziZADGVZQAyZXNsjUN/d33H2PeP92bvyBFCkCJQIrGaXPHA7BtXwtfe+sS/vCJcymNJZNDPBrJ2ln8+Oa9eY1RpBDUWSxF44KFkzl/wUTesHQqiXiUmeMrUsdKYxE1AUnRUiKQohGNGDe+6xVZj8WjSgRSvNQ0JEIyETz0dH0qGdy2ciu7m9pTx7u1sL2MYqElAjP7oZnVmdm6gxw3M/ummW0ys6fM7OSwYhE5lJf2trC7qZ2fPLqFHQ2tfOL2pzj9Kw+ljrcPso6ByEgXZo3gx8CFgxy/CJgXPK4CvhNiLCJDcvfaHanJ6NJHEWVb9F5ktAgtEbj7I8BgQy4uBW7ypMeAGjM7Jqx4RIbiby/t56qfDpxYVzUCGc0K2UcwlcwlMLcFZQOY2VVmttLMVtbX1+clOCkuj37qlYMeV41ARrMR0Vns7je4+zJ3X1ZbW1vocGQUmlIzcJ2lH7/7FVxz/jyAjHUMREabQiaC7cD0tP1pQZlIQVy4aHJquyQW4Zz5tSyZPgZQIpDRrZCJ4C7gHcHooRVAg7vvONSTRMLyjcuXsGLOOAAmVJRgZiSCO4+1jKWMZqHdUGZmPwfOBSaY2Tbgc0AcwN2/C9wDXAxsAlqAd4cVi8hQlMaizJ5QyWMv7GVCVWmyLJifKL1G0NDaycdvW8P0seW8ZtEkTp0zviDxiuRKaInA3S8/xHEHrg7r/UWOxJiyOEBq+olEMGNpW2cPXd09tHX1cP29T3P/hl0A/PDPm9ly/WsLE6xIjmiKCZE0vTOUThmTAPrWMGjv6ubaW57k7rU7WDqjpmDxiYRhRIwaEsmXfS0dQN/01KXBMpbtnT3cvTbZhbVtX2thghMJiRKBSJq5tckmoZOmJX/199YI2tJuKKs/0D7wiSIjmJqGRNJccepMls0ax/HHVANpiUDDR2UUU41AJE0kYqkkAJAImob2tXRmPT+RZflLkZFGn2KRQcSiERZMruI7v38+o/yChZMAqE7ECxGWSE4pEYgcwuwJFQPKvvbWxbz5lGlolQIZDZQIRA7hI6+az6VLpvDHT56XKqtKxKksjdEe9B38dt1OHty4q1AhihwVdRaLHMJxk6v4xtuXDljKsjQeoS2YeuKDP0tOXa2by2QkUo1AZIji0eR/l2jEgOSUFB1dPfRoGUsZ4VQjEDkMN71nearPoHfE0I7GttTxf717AxcsnMzy2eMKEp/IkVAiEDkMZ8/vWw+jNJiZdFNdU6rs+3/czK7GdiUCGVHUNCRyhHprBM/tOpBR3tTeVYhwRI6YEoHIEepdq+BLd2/MKH/o6To+efsa6g60ZXuayLCjRCByhEoHuav41pXb+PUarbMkI4MSgcgR6q0RHExTm5qIZGRQIhA5Qs0dyS/6RDzCY9edz4fOncvly6cPOC4y3CkRiByhSdXJxWu+8sYTmTwmwScvXJAaSQTQHHQaf/6u9TyxeW9BYhQZCiUCkSO0Ys54/vCJc7ls6bRU2ZnHTkhtN7d30dzexY8f3cJbv/eXQoQoMiRKBCJHoXdt416vWjiJDV98DQsmV9Hc0c3upsxFbNo6u+noypyqQqTQlAhEcqy8JEZFaYzm9q6M1cwaWjt5zX89wgmfv4+X92u5Sxk+dGexSAgqSmPsaWrnX+/pu8dg8Rd+l9p+dtcBptSUFSI0kQGUCERCUFka5ZFnGw96vE7rHsswoqYhkRCUlwz+G6teiUCGESUCkRBUlmYmgsnVCU6eUcPmr1xMVSJGXePA6Sd+8ugWzrj+oXyFKJKipiGREJSXJO8nmFBZwt3XnMWYsjhmYGZMrCrN2jT0ubvWA9DZ3ZNa+0AkH5QIREJQmUj+15o5viJ141mviVUJdmWpEfRq6ehmTJkSgeRPqJ82M7vQzJ4xs01m9qksx99lZvVm9mTweF+Y8Yjky+tOmsLrFk/hHafNHHBsSk0Z2/e3squxjf0tHQOOt3Z05yNEkZTQagRmFgW+DVwAbAP+amZ3ufuGfqf+n7t/OKw4RAph+rhyvnX50qzHZk8o547V7Zz65QcB+NpbF/OGJVNTxzVHkeRbmDWC5cAmd3/B3TuAW4BLQ3w/kRFh9oTKjP2P3rqGy7//WGq/t0bwz79ay7cf3pTX2KQ4hZkIpgJb0/a3BWX9vcnMnjKz281sepbjIqNK75rH6R5Pm5SuJUgEP3vsJb563zN5i0uKV6F7pH4NzHL3k4D7gZ9kO8nMrjKzlWa2sr6+Pq8BiuRatkQApPoT1DQk+RZmItgOpP/CnxaUpbj7HnfvHUf3A+CUbC/k7je4+zJ3X1ZbW5vtFJERo6wkc0GbCxdN5soVM3nTyclZTFs7uunq7puY7nfrd+Y1Pik+YSaCvwLzzGy2mZUAbwfuSj/BzI5J2309kLn4q8goZZb889zjarn+TSfyL284gbHlJUBy+uqG1s7UuVf9dFVGYhDJtdASgbt3AR8G7iP5BX+ru683sy+a2euD064xs/Vmtga4BnhXWPGIDCdfvuxEAL7796dQEySA8tJkTaG1s5v9aYkA4DN3rqO7x/MbpBSNUG8oc/d7gHv6lX02bfs64LowYxAZji5fPoPLl8/IKOu9G7m5vZv9LZmJ4OdPbOWiE47h7PlqGpXcK3RnsYgEErEoZvDUtv089sKeAcf/8KwGSkg4lAhEholIxHCHe9ftzBg2+vW3LebEqWNY/dK+AkYno5kSgcgwtu4Lr+GypdOYPaGCPU3J6Si2B6ubdXX38PMnXmJf88BpKkQOhyadExlG7r7mTCZWJahKxKg/0J6aznpcRQl7mzt4YMMu3nfTSn70rlfQ1eNc94u13PDICzz88XMLG7iMaEoEIsPIoiljUtvTx5WntsdXlNDU3sVn7lwHwJ1PbqcqEQdg8+5mtu5tyThf5HCoaUhkBBhXmRxiuqMhOX31n5/fw33rdzKnNnmX8u+fqStYbDLyKRGIjADjK0pT25OqS6k/0E7dgXY+/7pFjK8oYcOOgesjf+zWNZzz1Yd5cU9zPkOVEUiJQGQEGB/UCCZXJ7jxna8A4ISp1Zw1bwLTxpVz55Mv86fndmc8547V23hxTwt/e2l/3uOVkUWJQGQEqChJductnFLNgslVvPbEY/inixdiZkyrKaOlo5v337SSbftauG/9Tj5yy99Sz822+I1IOnUWi4wAxx9TxWcuWcgbl04lFo3w7StOTh0bW5HsNG7t7Oaqm1axt7mDnWlLYfafrkKkPyUCkRHAzHjvmbOzHmvvTE5It2LOOB57Ye+A4/2nqxDpT01DIiPcta+axxtPnsqP3rWcCxdNHnB8Z0Mbd615Gfe+SevqDrTRo0nsJKAagcgIN21sOV976xIAZgfDSf/u1Bk0tHbyQn0zv12/k9+u38kfn61nbEUJcyZU8KlfrOUD58zhuouOL2ToMkwoEYiMIlefdywG/OMr51FWEuXKGx9PHbtt1baMc3/0py18+LxjUzemSfFS05DIKFJZGuOTFy5IrYJWf6A9deyChZNSy2RWlETp6O5hy+6WgsQpw4sSgcgo1nv/wap/fhXff8cylkyvAeCsecl1Dbbua6Gru4fO7h7++Fw9H/jpSpb/6wP89C9bChSxFIKahkRGsf9621J2NLQyvjJ5Z/LEquSf8ydV8tv18PHb1lAai3DKzLE8sLFvmorP3LmeK06dSSRiBYlb8ks1ApFRrLaqlJOm1aT2P3DOXC5dMoX3nDmbytIYLR3d7GvpTCWBRVOqedPJ0wDYti853XVPj9PYpiGoo5lqBCJFZFxFCd94+1IA5k6sZM3W/cybWElbVzc/f/8Kpo0tZ/VL+7hj9TbO/oPxhMMAAAvJSURBVOrD/Muli/jpYy/y7K4mZo0vZ+rYMj5w9lwtmTnKWPrY4pFg2bJlvnLlykKHITLi7WpsY1djGydOHYNZXxNQU3sXJ3zuvoxzF08bQ2UixvN1zUQMHvnkeWzf30o0YkyuTrB2ewObdzdz6ZKpRNWcNCyZ2Sp3X5btmGoEIkVqUnWCSdWJAeWVpTFu++Bp3LduJw9s3MXy2eO4/o0nEYkYv123kw/+bBU/fnQLX7p7I5Dsd6gLRie1dfbwd6fOyHi95+ubqK0qpVrDVIct1QhEZMg6uno45Uv3c6CtK+vxCxZO4pKTjuEPz9SzbNY4unp6+Oyd67lw0WS+e+UpeY5W0qlGICI5URKLcNEJk7l15TauXDGT/a2dXLp4Cs0dXfx23U7uXbeT+zfsAuAXf9ueet4DG3fxQn0T08aWUxKL4O7UHWjn5sde5C3Lpmt1tQJTjUBEDkt7Vzdbdrcwp7aCeLRv4OEdq7bx2TvXMaYszssNbVx93lxOmzOBPc3tXHvLkwBMGZNg8pgEq9PWSJhaU8ZtHzyNKTVlrNm6nx53KkpjfOOB56gpj/Ovl52Y92scjQarESgRiEhOuDvdPU5Xj9PS0c24iuTNbJ3dPcz7p3uzPueD58zlZ4+9SFN7F4un17Bm68BFdP7tTSfyyLO7mTG+nOWzx3FsbSXv/OETvOuMWVy5YiaNbV2MKYtz91M7+OitT3Llipn84/nzGFOmPol0SgQiUlCb6ppobu8iYkZbVzcGtHf1cPrc8XzxNxv40Z+3MLY8zpSaMkpiEWaNr6DuQBt/3rQHADM42FdVPGpcdMIx3LXm5VTZ2fNrueqsOXzvked58ynTWDFnPNGIcf+GXbx64aTUDXa9sX3o5lUcO7GS/7liYD+Gu2eMqhqplAhEZNiqa2zjmw89xzXnz2NiVd8opu37Wznj+od427LpfPENi7jlia3EoxEefX43W/e2sGZbQ+rc6kSMxrYuZk+oYFdjGy0d3QPep7I0RlN7spP78uUziEeN5vZu1r/cwNM7DwDwsQvmU1YSZUxZnPUvN7KjoZUnNu/lNYsm84/nz2NceQmPb97Dnzft5n1nzaG1o5uJ1aX831+3Up2Ic85xtUyoLMXdeWF3M3NrK4G+ZPLy/laa2ruIGBw7sWrg38WB5IJC6X8PuaJEICIjUv2BdiZUlgz4RV7X2MaPH93CVWfPoaa8BHdn7fYG5k+qoqO7h7XbGmho7eSBjbv4xertXLZ0KhEzzOD2YBbWkmiEykSM5vYurjl/Hl+975mjjnfOhAqWzRrLb57aQUtHN5cvn0FlaZSfP7GVWRPKWbe9MXXupy5awP0bduHuTKpO8FxdE5vqmqgqjXHrB08jYsZjL+zh5f2t/P6Zel7e38r7z57DNefPO6LYCpYIzOxC4BtAFPiBu1/f73gpcBNwCrAHeJu7bxnsNZUIRGSourp7aGzrSvVXuDuPb97LpOoEY8vjjCmL09ntlMSSNY2VW/Zx6ZIpNLV3MXN8BV3dPdSUl/CDP77Ar9e8zPxJVbR39bBkeg1rtu3npb0t/O2l/Vx84mTK4jHuXbeDiBndPU5rZ1+tpKIkSm1VKXuaOqgojWUsJdp7fNHUMTyxeeAKc73m1lbw/y5cwKuzLD40FAVJBGYWBZ4FLgC2AX8FLnf3DWnnfAg4yd0/aGZvBy5z97cN9rpKBCIyXHR297BtX2tqeu+24Mu/JBrBIbjjuolLF0/NmMBv9Uv7ONDWxbETK2nt6MpoJqprbOO+9TupTMQ4blI1+1s62NvSwauOn0QiHj3iWAuVCE4DPu/urwn2rwNw96+knXNfcM5fzCwG7ARqfZCglAhERA5foW4omwpsTdvfBpx6sHPcvcvMGoDxwO70k8zsKuCqYLfJzI60MW9C/9cuErru4lGM1wzFed2He80zD3ZgRNxZ7O43ADcc7euY2cqDZcTRTNddPIrxmqE4rzuX1xzmegTbgelp+9OCsqznBE1DY0h2GouISJ6EmQj+Cswzs9lmVgK8Hbir3zl3Ae8Mtt8MPDRY/4CIiOReaE1DQZv/h4H7SA4f/aG7rzezLwIr3f0u4Ebgp2a2CdhLMlmE6aibl0YoXXfxKMZrhuK87pxd84i7oUxERHJLaxaLiBQ5JQIRkSJXNInAzC40s2fMbJOZfarQ8eSSmf3QzOrMbF1a2Tgzu9/Mngv+HBuUm5l9M/h7eMrMTi5c5EfOzKab2cNmtsHM1pvZtUH5aL/uhJk9YWZrguv+QlA+28weD67v/4IBGphZabC/KTg+q5DxHw0zi5rZ38zsN8F+MVzzFjNba2ZPmtnKoCznn/GiSATBdBffBi4CFgKXm9nCwkaVUz8GLuxX9ingQXefBzwY7EPy72Be8LgK+E6eYsy1LuBj7r4QWAFcHfybjvbrbgde6e6LgSXAhWa2Avg34OvufiywD3hvcP57gX1B+deD80aqa4GNafvFcM0A57n7krR7BnL/GXf3Uf8ATgPuS9u/Driu0HHl+BpnAevS9p8Bjgm2jwGeCba/R3LOpwHnjeQHcCfJea2K5rqBcmA1yTv2dwOxoDz1eSc5au+0YDsWnGeFjv0IrnVa8KX3SuA3gI32aw7i3wJM6FeW8894UdQIyD7dxdQCxZIvk9x9R7C9E5gUbI+6v4ug6r8UeJwiuO6gieRJoA64H3ge2O/uvSvKp19bxjQuQO80LiPNfwGfBHqC/fGM/msGcOB3ZrYqmGoHQviMj4gpJuTouLub2agcJ2xmlcAdwEfcvTF93vrRet3u3g0sMbMa4JfAggKHFCozuwSoc/dVZnZuoePJszPdfbuZTQTuN7On0w/m6jNeLDWCoUx3MdrsMrNjAII/64LyUfN3YWZxkkngZnf/RVA86q+7l7vvBx4m2SxSE0zTApnXNhqmcTkDeL2ZbQFuIdk89A1G9zUD4O7bgz/rSCb95YTwGS+WRDCU6S5Gm/TpO95Jsg29t/wdwQiDFUBDWjVzxLDkT/8bgY3u/rW0Q6P9umuDmgBmVkayX2QjyYTw5uC0/tc9oqdxcffr3H2au88i+X/3IXe/glF8zQBmVmFmVb3bwKuBdYTxGS90Z0geO10uJrlQzvPAPxU6nhxf28+BHUAnyXbB95JsE30QeA54ABgXnGskR1A9D6wFlhU6/iO85jNJtp8+BTwZPC4ugus+CfhbcN3rgM8G5XOAJ4BNwG1AaVCeCPY3BcfnFPoajvL6zwV+UwzXHFzfmuCxvvd7K4zPuKaYEBEpcsXSNCQiIgehRCAiUuSUCEREipwSgYhIkVMiEBEpckoEUtTMrDuY2XGNma02s9MPcX6NmX1oCK/7ezMb8sLiZvbz4D6Xj5jZ5UN9nkguKBFIsWv15MyOi0lORviVQ5xfAxwyERyBWe6+GTgHeCSE1xc5KCUCkT7VJKczxswqzezBoJaw1swuDc65Hpgb1CK+Gpz7/4Jz1pjZ9Wmv95Zg7YBnzeysbG9oZjeb2QZgQTCR3KuBu83sfaFdpUg/mnROil1Z8AWcIDml7yuD8jbgMk9OZDcBeMzM7iI59/sJ7r4EwMwuAi4FTnX3FjMbl/baMXdfbmYXA58DXtX/zd39CjN7CzADuB34D3d/SziXKpKdEoEUu9a0L/XTgJvM7ASSt+t/2czOJjn18VT6pvtN9yrgR+7eAuDue9OO9U6Et4rkehEHczLJKQNOIjmdgEheKRGIBNz9L8Gv/1qS8xbVAqe4e2cw82XiMF+yPfizmyz/14KawpeB2cAlwfs1m9n57n7ekV2FyOFTH4FIwMwWAFGSUxaPITkHfqeZnQfMDE47AFSlPe1+4N1mVh68RnrT0KDc/R7gFJIry51IcmKxpUoCkm+qEUix6+0jgGRz0DvdvdvMbgZ+bWZrgZXA0wDuvsfM/mxm64B73f0TZrYEWGlmHcA9wKcP4/2XAmuC6dHj7t6YqwsTGSrNPioiUuTUNCQiUuSUCEREipwSgYhIkVMiEBEpckoEIiJFTolARKTIKRGIiBS5/w8FOHiLi+9v5AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Generating Loss Graphics\n",
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "qr71zYqr2y0D"
      },
      "outputs": [],
      "source": [
        "#Text to Text Translation\n",
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJvOFv0P2z3j",
        "outputId": "9ed2dc1e-b339-481f-dc36-d91c3a9e35f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "JqTKUVJL23H6"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "OdbEW8We25xS"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BooJVEbF27gL",
        "outputId": "8ce9fffe-671c-4bb5-c267-0303c5b8fbb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'CALL-BY-PHONE INTERNET', b'UP-TO-NOW FIRST-IN-LIST',\n",
              "       b'READ LATER_2', b'KIND whoa', b'FIRED LOOK'], dtype=object)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "VtcjLAoy3EzD"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "  \n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "XDxD1gEk3G62"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfRrefnP3JTu",
        "outputId": "52195995-fe92-441c-e42a-5fd666471866"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[ 637],\n",
              "       [ 305],\n",
              "       [ 649],\n",
              "       [ 520],\n",
              "       [1016]])>"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "QfLHBHfh3KHs"
      },
      "outputs": [],
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "    \n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "njYsu4RQ3O4k"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQUPdEIh3QY3",
        "outputId": "7e906e34-8394-45a9-e6d0-0a0e41007727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IX-1p RECENT-PAST DRINK TASTE FINE++ (1h)part:indef\n",
            "IX-1p NOT SEE (5)ACCIDENT part:indef IX-1p RECENT-PAST FUTURE NAME part:indef part:indef\n",
            "\n",
            "CPU times: user 582 ms, sys: 11.7 ms, total: 594 ms\n",
            "Wall time: 589 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'I just drank it and it tastes fine.',\n",
        "    'I just read a book.',\n",
        "])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "ClmftsMJBUpH"
      },
      "outputs": [],
      "source": [
        "#Generating Output text\n",
        "test_file = \"sentencesTest.txt\"\n",
        "outputfile = \"sign_rahaman_nmt_v28.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "iPi6jpLRnxm-"
      },
      "outputs": [],
      "source": [
        "# print(predicted['text'][0].numpy().decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "j8X7HWHNqW9u"
      },
      "outputs": [],
      "source": [
        "out = open(outputfile, \"w\")\n",
        "\n",
        "with open(test_file, encoding=\"unicode_escape\" ) as f:\n",
        "    lines_test = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "for sent in lines_test:\n",
        "    list_data = []\n",
        "    list_data.append(sent)\n",
        "    input_text = tf.constant(list_data)\n",
        "    result = translator.translate(input_text = input_text)\n",
        "    translated = result['text'][0].numpy().decode().replace(\" \", \",\")\n",
        "    out.write(translated+'\\n')\n",
        "\n",
        "out.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sign_MT_A5_V7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
